{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SQLContext\n",
    "from pyspark import SparkContext\n",
    "from pyspark.sql.types import *\n",
    "import pyspark.sql.functions as F\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "import string\n",
    "from nltk.stem.wordnet import WordNetLemmatizer\n",
    "sqlContext = SQLContext(sc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The OpenSubtitle dataset is stored in XML format. In order to process the dataset using spark, we will use the spark xml package from databricks (https://github.com/databricks/spark-xml). When using spark XML, you can either let spark-XML infer the schema of the XML file or you can specify it yourself. Letting spark-xml specify the schema for you is convenient however it is very expensive which we experienced ourselves. In order to speed up input pipeline, we will specify or own static xml schema below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "sourceSchema = StructType([\\\n",
    "                            StructField('genre', StringType()),\n",
    "                            StructField('year', StringType()),\n",
    "                          ])\n",
    "\n",
    "subtitleSchema = StructType([\\\n",
    "                            StructField('duration', StringType())\n",
    "                          ])\n",
    "\n",
    "conversionSchema =  StructType([\\\n",
    "                            StructField('sentences', StringType()),\n",
    "                            StructField('tokens', StringType())\n",
    "                          ])\n",
    "\n",
    "metaSchema = StructType([\\\n",
    "                            StructField('source', sourceSchema),\n",
    "                            StructField('conversion', conversionSchema),\n",
    "                            StructField('subtitle', subtitleSchema),\n",
    "                          ])\n",
    "\n",
    "wType = ArrayType(StructType([\\\n",
    "                       StructField('_VALUE', StringType())\n",
    "                   ]))\n",
    "\n",
    "sSchema = StructType([\\\n",
    "                      StructField('w', wType)\n",
    "    \n",
    "])\n",
    "\n",
    "sentenceSchema = ArrayType(sSchema)\n",
    "\n",
    "schema = StructType([\n",
    "    StructField('_id', IntegerType()),\n",
    "    StructField('meta', metaSchema)\n",
    "])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- _id: integer (nullable = true)\n",
      " |-- meta: struct (nullable = true)\n",
      " |    |-- source: struct (nullable = true)\n",
      " |    |    |-- genre: string (nullable = true)\n",
      " |    |    |-- year: string (nullable = true)\n",
      " |    |-- conversion: struct (nullable = true)\n",
      " |    |    |-- sentences: string (nullable = true)\n",
      " |    |    |-- tokens: string (nullable = true)\n",
      " |    |-- subtitle: struct (nullable = true)\n",
      " |    |    |-- duration: string (nullable = true)\n",
      "\n",
      "+-------+--------------------+\n",
      "|    _id|                meta|\n",
      "+-------+--------------------+\n",
      "|6950023|[[Action,Adventur...|\n",
      "|3602733|[[Comedy,Drama,Ro...|\n",
      "|3602678|[[Comedy,Drama,Ro...|\n",
      "|3585549|[[Comedy,Drama,Ro...|\n",
      "|3602669|[[Comedy,Drama,Ro...|\n",
      "|3602753|[[Comedy,Drama,Ro...|\n",
      "|3602659|[[Comedy,Drama,Ro...|\n",
      "|6988060|[[Action,Adventur...|\n",
      "|7008412|[[Action,Drama,Sc...|\n",
      "|7070230|[[Crime,Drama, 20...|\n",
      "|7070263|[[Crime,Drama, 20...|\n",
      "|7070270|[[Crime,Drama, 20...|\n",
      "|7070229|[[Crime,Drama, 20...|\n",
      "+-------+--------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df = sqlContext.read.format('com.databricks.spark.xml')\\\n",
    "    .options(rowTag='document', samplingRatio=0.0)\\\n",
    "    .load('[12][0-9][0-9][0-9]/**/*.xml.gz', schema=schema)\n",
    "df.printSchema()\n",
    "df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nwords_in_sentence = F.udf(lambda z: __builtins__.sum(list(map(lambda x: len(x), z))), IntegerType())\\n\\nmeta_data_df = df.withColumn(\"sentences\", F.col(\\'s.w\\'))\\nmeta_data_df = meta_data_df.withColumn(\"number_of_sentences\", F.size(F.col(\\'sentences\\')))\\nmeta_data_df = meta_data_df.withColumn(\"number_of_words\", words_in_sentence(F.col(\\'sentences\\')))\\n'"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "words_in_sentence = F.udf(lambda z: __builtins__.sum(list(map(lambda x: len(x), z))), IntegerType())\n",
    "\n",
    "meta_data_df = df.withColumn(\"sentences\", F.col('s.w'))\n",
    "meta_data_df = meta_data_df.withColumn(\"number_of_sentences\", F.size(F.col('sentences')))\n",
    "meta_data_df = meta_data_df.withColumn(\"number_of_words\", words_in_sentence(F.col('sentences')))\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Extract meta data about each movie:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+--------------------+----+---------+-----+------------+\n",
      "|    _id|               genre|year|sentences|words|    duration|\n",
      "+-------+--------------------+----+---------+-----+------------+\n",
      "|3602669|Comedy,Drama,Romance|2020|      364| 3035|  00:00:2,00|\n",
      "|6988060|Action,Adventure,...|2018|       21|  144|00:02:26,144|\n",
      "|7070229|         Crime,Drama|2018|     1322| 7312|00:42:41,066|\n",
      "+-------+--------------------+----+---------+-----+------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "movies = df.select(\\\n",
    "               F.col(\"_id\"),\\\n",
    "               F.col(\"meta.source.genre\").alias(\"genre\"),\\\n",
    "               F.col(\"meta.source.year\").alias(\"year\"),\\\n",
    "               F.col(\"meta.conversion.sentences\").alias(\"sentences\"),\\\n",
    "               F.col(\"meta.conversion.tokens\").alias(\"words\"),\\\n",
    "               F.col(\"meta.subtitle.duration\").alias(\"duration\"))  \n",
    "movies.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Extract the 10 most common words in each movies:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    }
   ],
   "source": [
    "stop_words=set(stopwords.words('english'))\n",
    "punctuation_list=list(string.punctuation)\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "\n",
    "from nltk.stem import PorterStemmer\n",
    "ps = PorterStemmer()\n",
    "\n",
    "print(\"and\" in stop_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+-----+\n",
      "|       word|count|\n",
      "+-----------+-----+\n",
      "|        ...|  226|\n",
      "|      still|   49|\n",
      "|     outfit|    3|\n",
      "|     waters|    2|\n",
      "|  connected|    1|\n",
      "|  peacefume|    1|\n",
      "|   randomly|    1|\n",
      "|     spared|    1|\n",
      "|       earl|    1|\n",
      "|  recognize|    1|\n",
      "|     online|    2|\n",
      "|     harder|    3|\n",
      "|       hope|   12|\n",
      "|      inner|    1|\n",
      "|    jewelry|    2|\n",
      "|secondguess|    1|\n",
      "|      trail|    2|\n",
      "|      1970s|    3|\n",
      "|  traveling|    1|\n",
      "|      oscar|    5|\n",
      "+-----------+-----+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "words_df = (\n",
    "    df.select(F.explode(F.col('s.w')))\n",
    "        .rdd\n",
    "        .flatMap(lambda x: x['col'])\n",
    "        .map(lambda x: x['_VALUE'].lower())\n",
    "        .filter(lambda x: x not in punctuation_list and len(x) > 2)\n",
    "        .map(lambda x: (lemmatizer.lemmatize(x,'v'), 1))\n",
    "        .filter(lambda x: x[0] not in stop_words and len(x[0]) > 2)\n",
    "        .reduceByKey(lambda x,y: x + y)\n",
    "        .takeOrdered(20, key = lambda x: -x[1])\n",
    ")\n",
    "words_df\n",
    "\"\"\"\n",
    "lemmatize = F.udf(lambda x: lemmatizer.lemmatize(x, 'v'), StringType())\n",
    "\n",
    "cc = df.select(F.explode(F.col('s.w')))\n",
    "cc = cc.select(F.explode(F.col('col')['_VALUE']))\n",
    "cc = cc.select(F.lower(F.col('col')).alias('word'))\n",
    "cc = cc.filter((cc.word.isin(stop_words) == False) & (cc.word.isin(punctuation_list) == False))\n",
    "cc = cc.groupby('word').count()\n",
    "cc.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = sqlContext.read.parquet('movies_sample_v2.parquet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "17702"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+-----+\n",
      "|  year|count|\n",
      "+------+-----+\n",
      "|  2020|    2|\n",
      "|  2017| 1708|\n",
      "|  2016| 2442|\n",
      "|  2015| 1479|\n",
      "|  2014|   75|\n",
      "|  2013|  740|\n",
      "|  2012|    4|\n",
      "|  2011|  960|\n",
      "|  2010|  670|\n",
      "|  2009|    2|\n",
      "|  2008| 1587|\n",
      "|  2007| 1012|\n",
      "|  2006| 1405|\n",
      "|  2005|  305|\n",
      "|  2004|   13|\n",
      "|  2003|    8|\n",
      "|  2000|  702|\n",
      "|  1999|    4|\n",
      "|  1997|    1|\n",
      "|1996??|    7|\n",
      "|  1996|  505|\n",
      "|  1994|    1|\n",
      "|  1993|  408|\n",
      "|  1991|  289|\n",
      "|  1990|  353|\n",
      "|  1989|  275|\n",
      "|  1988|  270|\n",
      "|  1987|    1|\n",
      "|  1984|    3|\n",
      "|  1982|  169|\n",
      "|  1978|    1|\n",
      "|  1977|   71|\n",
      "|  1975|  160|\n",
      "|  1974|    2|\n",
      "|  1970|  137|\n",
      "|  1969|  158|\n",
      "|  1968|  148|\n",
      "|  1967|    6|\n",
      "|  1966|  155|\n",
      "|  1965|  127|\n",
      "|  1964|  140|\n",
      "|  1962|   72|\n",
      "|  1961|   77|\n",
      "|  1960|    1|\n",
      "|  1959|   69|\n",
      "|  1958|   93|\n",
      "|  1956|   86|\n",
      "|  1955|   67|\n",
      "|  1954|    1|\n",
      "|  1952|   50|\n",
      "|  1948|   53|\n",
      "|  1947|   35|\n",
      "|  1946|   40|\n",
      "|  1945|   38|\n",
      "|  1944|   33|\n",
      "|  1943|   35|\n",
      "|  1940|   36|\n",
      "|  1939|   43|\n",
      "|  1938|   32|\n",
      "|  1936|   39|\n",
      "|  1935|   30|\n",
      "|  1934|   24|\n",
      "|  1929|    1|\n",
      "|  1928|   10|\n",
      "|  1927|    8|\n",
      "|  1926|    7|\n",
      "|  1925|    8|\n",
      "|  1924|    1|\n",
      "|  1922|    3|\n",
      "|  1918|    2|\n",
      "|  1916|    5|\n",
      "|  1906|    2|\n",
      "|  null|  196|\n",
      "+------+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.groupby('year').count().sort(F.desc(\"year\")).show(100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
